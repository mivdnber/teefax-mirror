DS,Inserter
SP,page15.html
DE,Autogenerated from BBC News: https://www.bbc.com/news/technology-48349102
PN,11900
CT,15,C
SC,1
PS,8040
MS,0
OL,0,XXXXXXXXCEEFAX 1 mpp DAY dd MTH hh:nn/ss
OL,1,[Wj#3kj#3kj#3k[T[][S |,h<$|h<$|0|h<$|,      
OL,2,[Wj $kj $kj 'k[T[][S sju0jw1)ju0s      
OL,3,[W"###"###"###[T///,,-,.,-,.,/,-,.,,//////
OL,24,ANext NewsBNews IndxCHeadlinesFMain Menu
FL,120,102,101,100,F,109
OL,4,C'Alexa, are you perpetuating bias?'
OL,5, AI-powered voice assistants with female
OL,6, voices are perpetuating harmful gender
OL,7, biases, according to a UN study.
OL,9,FThese female helpers are portrayed as
OL,10,F"obliging and eager to please",
OL,11,Freinforcing the idea that women are
OL,12,F"subservient", it finds.
OL,14,FParticularly worrying, it says, is how
OL,15,Fthey often give "deflecting, lacklustre
OL,16,For apologetic responses" to insults.
OL,18,FThe report calls for technology firms
OL,19,Fto stop making voice assistants female
OL,20,Fby default.
@